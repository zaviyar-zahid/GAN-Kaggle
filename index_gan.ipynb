{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1470d89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from colorama import Fore, Back, Style\n",
    "y_ = Fore.YELLOW\n",
    "r_ = Fore.RED\n",
    "g_ = Fore.GREEN\n",
    "b_ = Fore.BLUE\n",
    "m_ = Fore.MAGENTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbe55b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from PIL import Image\n",
    "import tensorflow_addons as tfa\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90a1c6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of replicas: 1\n",
      "2.10.1\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Device:', tpu.master())\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "except:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "print('Number of replicas:', strategy.num_replicas_in_sync)\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "AUTO = tf.data.experimental.AUTOTUNE    \n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcaeda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to load the input images and set its dimensions to 1024 x 768\n",
    "def load_image(image_path):\n",
    "    max_dim=512\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_image(img, channels=3)# decodes the image into a tensor\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "\n",
    "    shape = tf.cast(tf.shape(img)[:-1], tf.float32)\n",
    "    long_dim = max(shape)\n",
    "    scale = max_dim / long_dim\n",
    "    new_shape = tf.cast(shape * scale, tf.int32)\n",
    "\n",
    "    img = tf.image.resize(img, new_shape)\n",
    "    img = img[tf.newaxis, :]# broadcasting the image array so that it has a batch dimension\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dc83cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(image, title=None):\n",
    "    if(len(image.shape) > 3):# suppose dim is like 1,2,4,2,2,1... it removes the ones so that only 3 values remain W,H,c\n",
    "        image=np.squeeze(image, axis=0)\n",
    "    plt.imshow(image)\n",
    "    if(title):\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22544743",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_img=load_image('../input/gan-getting-started/photo_jpg/00068bc07f.jpg')\n",
    "style_img=load_image('../input/gan-getting-started/monet_jpg/2f90c99e10.jpg')\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.subplot(1, 2, 1)\n",
    "imshow(content_img, 'Base Target Image')\n",
    "plt.subplot(1, 2, 2)\n",
    "imshow(style_img, 'Style image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64e40c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_img=load_image('../input/gan-getting-started/photo_jpg/00068bc07f.jpg')\n",
    "style_img=load_image('../input/gan-getting-started/monet_jpg/2f90c99e10.jpg')\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.subplot(1, 2, 1)\n",
    "imshow(content_img, 'Base Target Image')\n",
    "plt.subplot(1, 2, 2)\n",
    "imshow(style_img, 'Style image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c0fc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(content_img.shape)\n",
    "print(style_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b971f4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the content image representation and load the model\n",
    "x=tf.keras.applications.vgg19.preprocess_input(content_img*255)# needs preprocessing for the model to be initialized\n",
    "x=tf.image.resize(x, (256,256))# the vgg19 model takes images in 256\n",
    "vgg_model=tf.keras.applications.VGG19(include_top=False, weights='imagenet')\n",
    "vgg_model.trainable=False\n",
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc81102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chooose the content and style layers\n",
    "content_layers=['block4_conv2']\n",
    "style_layers = ['block1_conv1',\n",
    "                'block2_conv1',\n",
    "                'block3_conv1', \n",
    "                'block4_conv1', \n",
    "                'block5_conv1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2d8429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "def my_model(layer_names):\n",
    "    # Retrieve the output layers corresponding to the content and style layers\n",
    "    vgg_model = tf.keras.applications.VGG19(include_top=False, weights='imagenet')\n",
    "    vgg_model.trainable = False\n",
    "    outputs = [vgg_model.get_layer(name).output for name in layer_names]\n",
    "    model=tf.keras.Model([vgg_model.input], outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c4f114",
   "metadata": {},
   "outputs": [],
   "source": [
    "style_extractor = my_model(style_layers)\n",
    "style_outputs = style_extractor(style_img*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746551a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the gram matrix\n",
    "# Einsum allows defining Tensors by defining their element-wise computation.\n",
    "# This computation is defined by equation, a shorthand form based on Einstein summation.\n",
    "def gram_matrix(input_tensor): # input_tensor is of shape ch, n_H, n_W\n",
    "    result = tf.linalg.einsum('bijc,bijd->bcd', input_tensor, input_tensor)\n",
    "    input_shape = tf.shape(input_tensor)\n",
    "    num_locations = tf.cast(input_shape[1]*input_shape[2], tf.float32) # Unrolls n_H and n_W\n",
    "    return result/(num_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9f4126",
   "metadata": {},
   "outputs": [],
   "source": [
    "class entire_model(tf.keras.models.Model):\n",
    "    def __init__(self, style_layers, content_layers):\n",
    "        super(entire_model, self).__init__()\n",
    "        self.vgg=my_model(style_layers + content_layers)\n",
    "        self.style_layers=style_layers\n",
    "        self.content_layers=content_layers\n",
    "        self.num_style_layers=len(style_layers)\n",
    "        self.vgg.trainable=False\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs=inputs*255.0 # Scale back the pixel values\n",
    "        preprocessed_input=tf.keras.applications.vgg19.preprocess_input(inputs)\n",
    "        outputs=self.vgg(preprocessed_input)# Pass the preprocessed input to my_model\n",
    "\n",
    "        # Separate the representations of style and content\n",
    "        style_outputs, content_outputs=(outputs[:self.num_style_layers], outputs[self.num_style_layers:])\n",
    "        # Calculate the gram matrix for each layer in the style output. This will be the final style representation\n",
    "        style_outputs=[gram_matrix(layer) for layer in style_outputs]\n",
    "\n",
    "        # Store the content and style representation in dictionaries in a layer by layer manner\n",
    "        content_dict = {content_name:value\n",
    "                    for content_name, value\n",
    "                    in zip(self.content_layers, content_outputs)}\n",
    "\n",
    "        style_dict = {style_name:value\n",
    "                  for style_name, value\n",
    "                  in zip(self.style_layers, style_outputs)}\n",
    "\n",
    "        return {'content': content_dict, 'style': style_dict}\n",
    "        # Returns a dict of dicts with content and style representations, i.e., gram matrix of the style_layers and\n",
    "        # the content of the content_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2846d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we extract the style and content features by calling the above class\n",
    "extractor=entire_model(style_layers, content_layers)\n",
    "style_targets = extractor(style_img)['style']\n",
    "content_targets = extractor(content_img)['content']\n",
    "\n",
    "results = extractor(tf.constant(content_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccb9baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "style_weight=40\n",
    "content_weight=10\n",
    "\n",
    "# Custom weights for different style layers\n",
    "style_weights = {'block1_conv1': 0.7,\n",
    "                 'block2_conv1': 0.19,\n",
    "                 'block3_conv1': 0.24,\n",
    "                 'block4_conv1': 0.11,\n",
    "                 'block5_conv1': 0.26}\n",
    "# style_weights = {'block1_conv1': 0.3,\n",
    "#                  'block2_conv1': 0.45,\n",
    "#                  'block3_conv1': 0.15,\n",
    "#                  'block4_conv1': 0.05,\n",
    "#                  'block5_conv1': 0.05}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f811c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_cost(outputs):\n",
    "    style_outputs=outputs['style']\n",
    "    content_outputs=outputs['content']\n",
    "    style_loss=tf.add_n([style_weights[name]*tf.reduce_mean((style_outputs[name]-style_targets[name])**2)\n",
    "                        for name in style_outputs.keys()])\n",
    "    style_loss*=style_weight/len(style_layers)# Normalize\n",
    "\n",
    "    content_loss = tf.add_n([tf.reduce_mean((content_outputs[name]-content_targets[name])**2)\n",
    "                             for name in content_outputs.keys()])\n",
    "    content_loss*=content_weight/len(content_layers)\n",
    "    loss=style_loss+content_loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9923190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a tf.Variable to contain the image to optimize\n",
    "generate_image = tf.Variable(content_img)\n",
    "# Since this is a float image, define a function to keep the pixel values between 0 and 1\n",
    "def clip_0_1(image):\n",
    "    return tf.clip_by_value(image, clip_value_min=0.0, clip_value_max=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a96dbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.optimizers.Adam(learning_rate=0.02, beta_1=0.99, epsilon=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a35c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def train_step(image):\n",
    "    with tf.GradientTape() as tape:\n",
    "        outputs = extractor(image)\n",
    "        loss = total_cost(outputs)\n",
    "\n",
    "    grad = tape.gradient(loss, image)\n",
    "    opt.apply_gradients([(grad, image)])\n",
    "    image.assign(clip_0_1(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbd3984",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations=2500\n",
    "for i in range(num_iterations):\n",
    "    train_step(generate_image)\n",
    "    if(i%500==0):\n",
    "        plt.figure(figsize=(12,12))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        imshow(content_img, 'Original Image')\n",
    "        plt.subplot(1, 3, 2)\n",
    "        imshow(style_img, 'Style Image')\n",
    "        plt.subplot(1, 3, 3)\n",
    "        imshow(np.squeeze(generate_image.read_value(), 0), 'New Image - Step'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bbd591",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step(generate_image)\n",
    "plt.imshow(np.squeeze(generate_image.read_value(), 0))\n",
    "plt.axis('off')\n",
    "fig1 = plt.gcf()\n",
    "fig1.savefig('new_image.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a45972f",
   "metadata": {},
   "source": [
    "### Miscellaneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f095aec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "monet_jpg_directory = './GAN/monet_jpg/'\n",
    "photo_jpg_directory = './GAN/photo_jpg/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cf60696",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImagePaths(path):\n",
    "    image_names = []\n",
    "    for dirname, _, filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            fullpath = os.path.join(dirname, filename)\n",
    "            image_names.append(fullpath)\n",
    "    return image_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3c3de23",
   "metadata": {},
   "outputs": [],
   "source": [
    "monet_images_path = getImagePaths(monet_jpg_directory)\n",
    "photo_images_path = getImagePaths(photo_jpg_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "900e92b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./GAN/monet_jpg/000c1e3bff.jpg',\n",
       " './GAN/monet_jpg/011835cfbf.jpg',\n",
       " './GAN/monet_jpg/0260d15306.jpg',\n",
       " './GAN/monet_jpg/049e293b93.jpg',\n",
       " './GAN/monet_jpg/05144e306f.jpg',\n",
       " './GAN/monet_jpg/052a77c020.jpg',\n",
       " './GAN/monet_jpg/058f878b7c.jpg',\n",
       " './GAN/monet_jpg/05b493ff42.jpg',\n",
       " './GAN/monet_jpg/064487d630.jpg',\n",
       " './GAN/monet_jpg/066fe4cbaa.jpg',\n",
       " './GAN/monet_jpg/07fcaee35f.jpg',\n",
       " './GAN/monet_jpg/09b76b6471.jpg',\n",
       " './GAN/monet_jpg/0a5075d42a.jpg',\n",
       " './GAN/monet_jpg/0bd913dbc7.jpg',\n",
       " './GAN/monet_jpg/0e3b3292da.jpg',\n",
       " './GAN/monet_jpg/106757e5d8.jpg',\n",
       " './GAN/monet_jpg/1078363ff0.jpg',\n",
       " './GAN/monet_jpg/10c555c1b1.jpg',\n",
       " './GAN/monet_jpg/118da0690c.jpg',\n",
       " './GAN/monet_jpg/11ab570c5e.jpg',\n",
       " './GAN/monet_jpg/11be65b3e9.jpg',\n",
       " './GAN/monet_jpg/133b42e498.jpg',\n",
       " './GAN/monet_jpg/14162de938.jpg',\n",
       " './GAN/monet_jpg/14ff6e6a99.jpg',\n",
       " './GAN/monet_jpg/158740962c.jpg',\n",
       " './GAN/monet_jpg/16dabe418c.jpg',\n",
       " './GAN/monet_jpg/17557a29cb.jpg',\n",
       " './GAN/monet_jpg/1814cc6632.jpg',\n",
       " './GAN/monet_jpg/184d6c66cd.jpg',\n",
       " './GAN/monet_jpg/1994b8d4a2.jpg',\n",
       " './GAN/monet_jpg/19dc36ccb2.jpg',\n",
       " './GAN/monet_jpg/1a127acf4d.jpg',\n",
       " './GAN/monet_jpg/1e4e4e63c5.jpg',\n",
       " './GAN/monet_jpg/1f22663e72.jpg',\n",
       " './GAN/monet_jpg/1f9667f2a7.jpg',\n",
       " './GAN/monet_jpg/22b1ac6b44.jpg',\n",
       " './GAN/monet_jpg/23832dead5.jpg',\n",
       " './GAN/monet_jpg/23b07c3769.jpg',\n",
       " './GAN/monet_jpg/23d6aeb485.jpg',\n",
       " './GAN/monet_jpg/23f0fbd77e.jpg',\n",
       " './GAN/monet_jpg/24af733334.jpg',\n",
       " './GAN/monet_jpg/252d9a4abc.jpg',\n",
       " './GAN/monet_jpg/2581464ddc.jpg',\n",
       " './GAN/monet_jpg/25c9904782.jpg',\n",
       " './GAN/monet_jpg/26b66eb819.jpg',\n",
       " './GAN/monet_jpg/2759c1ed37.jpg',\n",
       " './GAN/monet_jpg/281b73fb5e.jpg',\n",
       " './GAN/monet_jpg/28deb43a71.jpg',\n",
       " './GAN/monet_jpg/295eb5c521.jpg',\n",
       " './GAN/monet_jpg/29696b4455.jpg',\n",
       " './GAN/monet_jpg/2acfbab228.jpg',\n",
       " './GAN/monet_jpg/2c00f5147f.jpg',\n",
       " './GAN/monet_jpg/2cca56415e.jpg',\n",
       " './GAN/monet_jpg/2e0d0e6e19.jpg',\n",
       " './GAN/monet_jpg/2f20944b6a.jpg',\n",
       " './GAN/monet_jpg/2f90c99e10.jpg',\n",
       " './GAN/monet_jpg/3283442e33.jpg',\n",
       " './GAN/monet_jpg/32cc820303.jpg',\n",
       " './GAN/monet_jpg/32e33792cc.jpg',\n",
       " './GAN/monet_jpg/3417ace946.jpg',\n",
       " './GAN/monet_jpg/344d1829bb.jpg',\n",
       " './GAN/monet_jpg/3545597386.jpg',\n",
       " './GAN/monet_jpg/369f6d07e8.jpg',\n",
       " './GAN/monet_jpg/3843e221cc.jpg',\n",
       " './GAN/monet_jpg/3b262c6726.jpg',\n",
       " './GAN/monet_jpg/3c341ff93e.jpg',\n",
       " './GAN/monet_jpg/3d13fe022e.jpg',\n",
       " './GAN/monet_jpg/3deea9f4a4.jpg',\n",
       " './GAN/monet_jpg/3eaef3ee43.jpg',\n",
       " './GAN/monet_jpg/40d7d18ad3.jpg',\n",
       " './GAN/monet_jpg/417e77e946.jpg',\n",
       " './GAN/monet_jpg/4260d1c556.jpg',\n",
       " './GAN/monet_jpg/429e382095.jpg',\n",
       " './GAN/monet_jpg/463835bbc6.jpg',\n",
       " './GAN/monet_jpg/4660310c3e.jpg',\n",
       " './GAN/monet_jpg/47a0548067.jpg',\n",
       " './GAN/monet_jpg/488600cb75.jpg',\n",
       " './GAN/monet_jpg/49337b68f4.jpg',\n",
       " './GAN/monet_jpg/4995c04b1a.jpg',\n",
       " './GAN/monet_jpg/4ab2583fe2.jpg',\n",
       " './GAN/monet_jpg/4ad8b366c1.jpg',\n",
       " './GAN/monet_jpg/4b0adf7c6f.jpg',\n",
       " './GAN/monet_jpg/4bb4ca7b03.jpg',\n",
       " './GAN/monet_jpg/4c0e35882c.jpg',\n",
       " './GAN/monet_jpg/4c74254ad3.jpg',\n",
       " './GAN/monet_jpg/4e05523825.jpg',\n",
       " './GAN/monet_jpg/4f045779b0.jpg',\n",
       " './GAN/monet_jpg/4f3f4ff590.jpg',\n",
       " './GAN/monet_jpg/4f4de0bbba.jpg',\n",
       " './GAN/monet_jpg/4f7e01f097.jpg',\n",
       " './GAN/monet_jpg/50855dd324.jpg',\n",
       " './GAN/monet_jpg/512cd171a9.jpg',\n",
       " './GAN/monet_jpg/5185e8c56a.jpg',\n",
       " './GAN/monet_jpg/51bdd25f76.jpg',\n",
       " './GAN/monet_jpg/51db3fc011.jpg',\n",
       " './GAN/monet_jpg/526a110636.jpg',\n",
       " './GAN/monet_jpg/52aed0f943.jpg',\n",
       " './GAN/monet_jpg/52d12dc627.jpg',\n",
       " './GAN/monet_jpg/52fc351abf.jpg',\n",
       " './GAN/monet_jpg/536aa87152.jpg',\n",
       " './GAN/monet_jpg/565f19268b.jpg',\n",
       " './GAN/monet_jpg/586acab7c5.jpg',\n",
       " './GAN/monet_jpg/5926f85cbf.jpg',\n",
       " './GAN/monet_jpg/593db29cce.jpg',\n",
       " './GAN/monet_jpg/599098859e.jpg',\n",
       " './GAN/monet_jpg/59df696966.jpg',\n",
       " './GAN/monet_jpg/5aa514ffac.jpg',\n",
       " './GAN/monet_jpg/5c79cfe0b3.jpg',\n",
       " './GAN/monet_jpg/5cb895b722.jpg',\n",
       " './GAN/monet_jpg/5e357ad790.jpg',\n",
       " './GAN/monet_jpg/5ffbfe68d4.jpg',\n",
       " './GAN/monet_jpg/6043aadea0.jpg',\n",
       " './GAN/monet_jpg/608ee0d370.jpg',\n",
       " './GAN/monet_jpg/61e735361a.jpg',\n",
       " './GAN/monet_jpg/632ddbc784.jpg',\n",
       " './GAN/monet_jpg/661e374153.jpg',\n",
       " './GAN/monet_jpg/66226e18fc.jpg',\n",
       " './GAN/monet_jpg/66a144f547.jpg',\n",
       " './GAN/monet_jpg/6742294320.jpg',\n",
       " './GAN/monet_jpg/676a5a4c2e.jpg',\n",
       " './GAN/monet_jpg/6782e7cb2a.jpg',\n",
       " './GAN/monet_jpg/68729aac07.jpg',\n",
       " './GAN/monet_jpg/68b60c04b7.jpg',\n",
       " './GAN/monet_jpg/68d60af226.jpg',\n",
       " './GAN/monet_jpg/695897bd4a.jpg',\n",
       " './GAN/monet_jpg/69f4b75a37.jpg',\n",
       " './GAN/monet_jpg/6a03aea8be.jpg',\n",
       " './GAN/monet_jpg/6bbe0e63c6.jpg',\n",
       " './GAN/monet_jpg/6bfbd1df5b.jpg',\n",
       " './GAN/monet_jpg/6c6cc46498.jpg',\n",
       " './GAN/monet_jpg/6d0e87f557.jpg',\n",
       " './GAN/monet_jpg/6e0429f92e.jpg',\n",
       " './GAN/monet_jpg/6ee7c39dbc.jpg',\n",
       " './GAN/monet_jpg/6f0b9df5c5.jpg',\n",
       " './GAN/monet_jpg/7017e6caa1.jpg',\n",
       " './GAN/monet_jpg/7054793632.jpg',\n",
       " './GAN/monet_jpg/70bc945f95.jpg',\n",
       " './GAN/monet_jpg/718445ebe3.jpg',\n",
       " './GAN/monet_jpg/7239ba0b55.jpg',\n",
       " './GAN/monet_jpg/730f325b64.jpg',\n",
       " './GAN/monet_jpg/732d76a469.jpg',\n",
       " './GAN/monet_jpg/7341d96c1d.jpg',\n",
       " './GAN/monet_jpg/73f33a12c5.jpg',\n",
       " './GAN/monet_jpg/74e452fb31.jpg',\n",
       " './GAN/monet_jpg/76cc7181f8.jpg',\n",
       " './GAN/monet_jpg/77b37629f2.jpg',\n",
       " './GAN/monet_jpg/79224da51f.jpg',\n",
       " './GAN/monet_jpg/79292e1434.jpg',\n",
       " './GAN/monet_jpg/7952021d2f.jpg',\n",
       " './GAN/monet_jpg/7960adbd50.jpg',\n",
       " './GAN/monet_jpg/7cb36714d0.jpg',\n",
       " './GAN/monet_jpg/7d64c3100c.jpg',\n",
       " './GAN/monet_jpg/8044a92484.jpg',\n",
       " './GAN/monet_jpg/8077b7e9e7.jpg',\n",
       " './GAN/monet_jpg/8114fa2607.jpg',\n",
       " './GAN/monet_jpg/815624563e.jpg',\n",
       " './GAN/monet_jpg/82991e742a.jpg',\n",
       " './GAN/monet_jpg/82b9fd68b1.jpg',\n",
       " './GAN/monet_jpg/8314acfd35.jpg',\n",
       " './GAN/monet_jpg/853f8d711f.jpg',\n",
       " './GAN/monet_jpg/85580214be.jpg',\n",
       " './GAN/monet_jpg/88402296cc.jpg',\n",
       " './GAN/monet_jpg/893db2701d.jpg',\n",
       " './GAN/monet_jpg/89964efa86.jpg',\n",
       " './GAN/monet_jpg/89d970411d.jpg',\n",
       " './GAN/monet_jpg/89fcbf2f76.jpg',\n",
       " './GAN/monet_jpg/8b54448a07.jpg',\n",
       " './GAN/monet_jpg/8b7948248f.jpg',\n",
       " './GAN/monet_jpg/8b841420b4.jpg',\n",
       " './GAN/monet_jpg/8c48e112d0.jpg',\n",
       " './GAN/monet_jpg/8c8011c291.jpg',\n",
       " './GAN/monet_jpg/8cfd45a2e2.jpg',\n",
       " './GAN/monet_jpg/8e5ff15568.jpg',\n",
       " './GAN/monet_jpg/8ee2933868.jpg',\n",
       " './GAN/monet_jpg/8f02369f42.jpg',\n",
       " './GAN/monet_jpg/910610e827.jpg',\n",
       " './GAN/monet_jpg/910729e0ce.jpg',\n",
       " './GAN/monet_jpg/92c0ba8c0d.jpg',\n",
       " './GAN/monet_jpg/93132f89ee.jpg',\n",
       " './GAN/monet_jpg/932d0dd808.jpg',\n",
       " './GAN/monet_jpg/95a53d7b0b.jpg',\n",
       " './GAN/monet_jpg/95b5f01a85.jpg',\n",
       " './GAN/monet_jpg/9843bc25c5.jpg',\n",
       " './GAN/monet_jpg/9908d1daa9.jpg',\n",
       " './GAN/monet_jpg/990ed28f62.jpg',\n",
       " './GAN/monet_jpg/9963d64ebf.jpg',\n",
       " './GAN/monet_jpg/99a51d3e25.jpg',\n",
       " './GAN/monet_jpg/99d94af5dd.jpg',\n",
       " './GAN/monet_jpg/9ae6552353.jpg',\n",
       " './GAN/monet_jpg/9d58456cc3.jpg',\n",
       " './GAN/monet_jpg/9d9a4fccfb.jpg',\n",
       " './GAN/monet_jpg/9db9843ed1.jpg',\n",
       " './GAN/monet_jpg/9f409e3376.jpg',\n",
       " './GAN/monet_jpg/9fc868e864.jpg',\n",
       " './GAN/monet_jpg/a030bc32e6.jpg',\n",
       " './GAN/monet_jpg/a06b54dfe9.jpg',\n",
       " './GAN/monet_jpg/a202b1b200.jpg',\n",
       " './GAN/monet_jpg/a210ceedc7.jpg',\n",
       " './GAN/monet_jpg/a4e4a61fb2.jpg',\n",
       " './GAN/monet_jpg/a59f3f5b89.jpg',\n",
       " './GAN/monet_jpg/a619072f82.jpg',\n",
       " './GAN/monet_jpg/a6291c2a1c.jpg',\n",
       " './GAN/monet_jpg/a642e9cb6f.jpg',\n",
       " './GAN/monet_jpg/a7977705be.jpg',\n",
       " './GAN/monet_jpg/a7d53885e8.jpg',\n",
       " './GAN/monet_jpg/a885da7b52.jpg',\n",
       " './GAN/monet_jpg/a8fbbe3eb1.jpg',\n",
       " './GAN/monet_jpg/a96b79a93f.jpg',\n",
       " './GAN/monet_jpg/aa76c7625a.jpg',\n",
       " './GAN/monet_jpg/ad0101d010.jpg',\n",
       " './GAN/monet_jpg/ad8ce41fc0.jpg',\n",
       " './GAN/monet_jpg/b1310da865.jpg',\n",
       " './GAN/monet_jpg/b13c0973ee.jpg',\n",
       " './GAN/monet_jpg/b1ea5d5a7d.jpg',\n",
       " './GAN/monet_jpg/b256e61a5d.jpg',\n",
       " './GAN/monet_jpg/b2ce76c750.jpg',\n",
       " './GAN/monet_jpg/b3adc75e7d.jpg',\n",
       " './GAN/monet_jpg/b44f24c048.jpg',\n",
       " './GAN/monet_jpg/b5c2fe7c4c.jpg',\n",
       " './GAN/monet_jpg/b76d52e05a.jpg',\n",
       " './GAN/monet_jpg/b99546090b.jpg',\n",
       " './GAN/monet_jpg/ba52f976af.jpg',\n",
       " './GAN/monet_jpg/baf6efabfe.jpg',\n",
       " './GAN/monet_jpg/bbc5ac4564.jpg',\n",
       " './GAN/monet_jpg/bc4b364a44.jpg',\n",
       " './GAN/monet_jpg/bf6db09354.jpg',\n",
       " './GAN/monet_jpg/c14505c1da.jpg',\n",
       " './GAN/monet_jpg/c1dc1a85a4.jpg',\n",
       " './GAN/monet_jpg/c2576267d4.jpg',\n",
       " './GAN/monet_jpg/c4622e3fb6.jpg',\n",
       " './GAN/monet_jpg/c67ba2060c.jpg',\n",
       " './GAN/monet_jpg/c68c52e8fc.jpg',\n",
       " './GAN/monet_jpg/c6c360756c.jpg',\n",
       " './GAN/monet_jpg/c6c88ce9c4.jpg',\n",
       " './GAN/monet_jpg/c78b4fa3a9.jpg',\n",
       " './GAN/monet_jpg/c7d8142152.jpg',\n",
       " './GAN/monet_jpg/cb50326950.jpg',\n",
       " './GAN/monet_jpg/cb9c553ded.jpg',\n",
       " './GAN/monet_jpg/cc2bb659f4.jpg',\n",
       " './GAN/monet_jpg/cd6623d07d.jpg',\n",
       " './GAN/monet_jpg/cdddf326e3.jpg',\n",
       " './GAN/monet_jpg/ce3e0daddd.jpg',\n",
       " './GAN/monet_jpg/ceb6cf5f31.jpg',\n",
       " './GAN/monet_jpg/cf6488d84c.jpg',\n",
       " './GAN/monet_jpg/cfc6fce7b5.jpg',\n",
       " './GAN/monet_jpg/d05cab011d.jpg',\n",
       " './GAN/monet_jpg/d087730b76.jpg',\n",
       " './GAN/monet_jpg/d14c1abdd4.jpg',\n",
       " './GAN/monet_jpg/d1d9748a64.jpg',\n",
       " './GAN/monet_jpg/d239dae42d.jpg',\n",
       " './GAN/monet_jpg/d4116437bb.jpg',\n",
       " './GAN/monet_jpg/d50049fbfc.jpg',\n",
       " './GAN/monet_jpg/d5b0c260a0.jpg',\n",
       " './GAN/monet_jpg/d6d6e625bd.jpg',\n",
       " './GAN/monet_jpg/d729785cb8.jpg',\n",
       " './GAN/monet_jpg/d754850d01.jpg',\n",
       " './GAN/monet_jpg/d7948c7635.jpg',\n",
       " './GAN/monet_jpg/d88482796d.jpg',\n",
       " './GAN/monet_jpg/d9e8704878.jpg',\n",
       " './GAN/monet_jpg/da72006ef5.jpg',\n",
       " './GAN/monet_jpg/dc33f0edbe.jpg',\n",
       " './GAN/monet_jpg/dcab49d080.jpg',\n",
       " './GAN/monet_jpg/dcf5ea1040.jpg',\n",
       " './GAN/monet_jpg/dd46691bd7.jpg',\n",
       " './GAN/monet_jpg/de6f71b00f.jpg',\n",
       " './GAN/monet_jpg/df64ac2dcb.jpg',\n",
       " './GAN/monet_jpg/e2253b87a0.jpg',\n",
       " './GAN/monet_jpg/e291f8144f.jpg',\n",
       " './GAN/monet_jpg/e3112413b1.jpg',\n",
       " './GAN/monet_jpg/e37407c747.jpg',\n",
       " './GAN/monet_jpg/e510a74d3c.jpg',\n",
       " './GAN/monet_jpg/e568f84fad.jpg',\n",
       " './GAN/monet_jpg/e753318d04.jpg',\n",
       " './GAN/monet_jpg/e88d9de918.jpg',\n",
       " './GAN/monet_jpg/e9580cd500.jpg',\n",
       " './GAN/monet_jpg/e9f5563817.jpg',\n",
       " './GAN/monet_jpg/e9f686534b.jpg',\n",
       " './GAN/monet_jpg/eb3cc5c559.jpg',\n",
       " './GAN/monet_jpg/ec3398cef9.jpg',\n",
       " './GAN/monet_jpg/ec78d80dbd.jpg',\n",
       " './GAN/monet_jpg/ed597655a0.jpg',\n",
       " './GAN/monet_jpg/ede9769cb3.jpg',\n",
       " './GAN/monet_jpg/ee7adac58f.jpg',\n",
       " './GAN/monet_jpg/f04c9d8e34.jpg',\n",
       " './GAN/monet_jpg/f0884db067.jpg',\n",
       " './GAN/monet_jpg/f0d789c4bc.jpg',\n",
       " './GAN/monet_jpg/f4413e97bd.jpg',\n",
       " './GAN/monet_jpg/f486c1655f.jpg',\n",
       " './GAN/monet_jpg/f7836c88eb.jpg',\n",
       " './GAN/monet_jpg/f821791c85.jpg',\n",
       " './GAN/monet_jpg/f84fb4516a.jpg',\n",
       " './GAN/monet_jpg/f96a8de9f3.jpg',\n",
       " './GAN/monet_jpg/fb3b06dcb2.jpg',\n",
       " './GAN/monet_jpg/fb806a2a1c.jpg',\n",
       " './GAN/monet_jpg/fb93438ff9.jpg',\n",
       " './GAN/monet_jpg/fba982625d.jpg',\n",
       " './GAN/monet_jpg/fc11d52502.jpg',\n",
       " './GAN/monet_jpg/fd63a333f1.jpg',\n",
       " './GAN/monet_jpg/fdf1530d95.jpg',\n",
       " './GAN/monet_jpg/ffd74c77ea.jpg']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monet_images_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25593923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mNumber of Monet images: \u001b[32m 300\n",
      "\n",
      "\u001b[33mNumber of Photo images: \u001b[32m 7038\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"{y_}Number of Monet images: {g_} {len(monet_images_path)}\\n\")\n",
    "print(f\"{y_}Number of Photo images: {g_} {len(photo_images_path)}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
